---
phase: 01-infrastructure
plan: 04
type: execute
wave: 4
depends_on: ["01-03"]
files_modified:
  - apps/agent/package.json
  - apps/agent/tsconfig.json
  - apps/agent/src/index.ts
  - apps/agent/src/worker.ts
  - apps/agent/src/memory-consolidation.ts
  - apps/agent/src/shutdown.ts
autonomous: true
requirements:
  - DATA-03
  - DATA-06

must_haves:
  truths:
    - "Main agent process starts, connects to Postgres and Redis, registers all tools, and is ready to accept commands"
    - "Worker process starts and listens for jobs from the BullMQ queue"
    - "Memory consolidation runs periodically and writes structured facts to memory_facts table"
    - "Graceful shutdown closes all connections (Postgres pool, Redis client, BullMQ workers) without data loss"
    - "Working memory is the LLM context window (DATA-03 documented, no implementation needed)"
  artifacts:
    - path: "apps/agent/src/index.ts"
      provides: "Main agent process entry point"
      exports: []
    - path: "apps/agent/src/worker.ts"
      provides: "BullMQ worker entry point for long-running tools"
      exports: []
    - path: "apps/agent/src/memory-consolidation.ts"
      provides: "Periodic memory consolidation job"
      exports: ["startConsolidation", "stopConsolidation"]
    - path: "apps/agent/src/shutdown.ts"
      provides: "Graceful shutdown handler for all connections"
      exports: ["registerShutdownHandlers"]
  key_links:
    - from: "apps/agent/src/index.ts"
      to: "packages/tools/src/index.ts"
      via: "createDefaultRegistry to set up all tools"
      pattern: "createDefaultRegistry"
    - from: "apps/agent/src/index.ts"
      to: "packages/db/src/client.ts"
      via: "imports db client for logging and state"
      pattern: "import.*@jarvis/db"
    - from: "apps/agent/src/worker.ts"
      to: "packages/tools/src/invoke.ts"
      via: "Worker processes tool invocation jobs"
      pattern: "invokeWithLogging"
    - from: "apps/agent/src/memory-consolidation.ts"
      to: "packages/db/src/schema/memory-facts.ts"
      via: "Inserts consolidated facts into memory_facts"
      pattern: "memoryFacts"
    - from: "apps/agent/src/shutdown.ts"
      to: "packages/db/src/client.ts"
      via: "Calls pool.end() on SIGTERM/SIGINT"
      pattern: "pool\\.end|shutdown"
---

<objective>
Create the main agent process, BullMQ worker, memory consolidation job, and graceful shutdown — wiring all packages together into a running system.

Purpose: This is the final assembly step. The agent process imports @jarvis/db, @jarvis/logging, and @jarvis/tools, creates the tool registry, starts the worker, launches memory consolidation, and registers shutdown handlers. After this plan, the Phase 1 infrastructure is complete and operational.

Output: `apps/agent` application that starts cleanly, connects to all services, registers all tools, runs memory consolidation, and shuts down gracefully.
</objective>

<execution_context>
@/Users/sn0w/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sn0w/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-infrastructure/01-RESEARCH.md
@.planning/phases/01-infrastructure/01-01-SUMMARY.md
@.planning/phases/01-infrastructure/01-02-SUMMARY.md
@.planning/phases/01-infrastructure/01-03-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create main agent process with tool registry and BullMQ worker</name>
  <files>
    apps/agent/package.json
    apps/agent/tsconfig.json
    apps/agent/src/index.ts
    apps/agent/src/worker.ts
    apps/agent/src/shutdown.ts
  </files>
  <action>
    Create the `apps/agent` application:

    1. **`apps/agent/package.json`**: `"name": "@jarvis/agent"`, `"type": "module"`, `"private": true`. Dependencies: `@jarvis/db` (workspace:*), `@jarvis/logging` (workspace:*), `@jarvis/tools` (workspace:*), `bullmq`, `dotenv`. DevDependencies: `@jarvis/typescript-config` (workspace:*), `tsx`. Scripts: `"build": "tsc"`, `"dev": "tsx --watch src/index.ts"`, `"start": "node dist/index.js"`, `"worker": "tsx src/worker.ts"`, `"worker:start": "node dist/worker.js"`.

    2. **`apps/agent/tsconfig.json`**: Extends `@jarvis/typescript-config/base.json`. Set `"outDir": "dist"`, `"rootDir": "src"`.

    3. **`apps/agent/src/shutdown.ts`** — Graceful shutdown:

       **`registerShutdownHandlers(resources: { pool, redis, worker?, consolidation? })`**:
       - Listen for `SIGTERM` and `SIGINT`
       - On signal: log "Shutting down..." to stderr, stop memory consolidation interval, close BullMQ worker (`worker.close()`), quit Redis (`redis.quit()`), end Postgres pool (`pool.end()`), then `process.exit(0)`
       - Set a 10-second force-kill timeout: if graceful shutdown doesn't complete in 10s, `process.exit(1)`
       - Per research anti-pattern guidance: ALWAYS call `pool.end()` to prevent connection leaks

    4. **`apps/agent/src/worker.ts`** — BullMQ worker entry point:

       ```typescript
       import 'dotenv/config';
       import { Worker } from 'bullmq';
       import { db } from '@jarvis/db';
       import { createDefaultRegistry, invokeWithLogging } from '@jarvis/tools';
       ```

       Create a BullMQ Worker listening on queue `'tool-execution'`. Connection via ioredis config from `REDIS_URL`. Concurrency: 5.

       Job handler: Extract `{ toolName, input, timeoutMs? }` from `job.data`. Call `invokeWithLogging(registry, db, toolName, input, timeoutMs)`. Return the ToolResult.

       Set `removeOnComplete: { age: 3600 }` and `removeOnFail: { age: 86400 }` per research guidance (don't let jobs accumulate in Redis).

       The worker creates its own tool registry via `createDefaultRegistry(db)`.

       Log worker startup to stderr: `"Worker started, listening for tool-execution jobs"`.

    5. **`apps/agent/src/index.ts`** — Main agent process:

       ```typescript
       import 'dotenv/config';
       import { db, pool } from '@jarvis/db';
       import { createDefaultRegistry, redis, invokeWithLogging } from '@jarvis/tools';
       import { logCycleStart } from '@jarvis/logging';
       import { Queue } from 'bullmq';
       import { startConsolidation } from './memory-consolidation.js';
       import { registerShutdownHandlers } from './shutdown.js';
       ```

       Startup sequence:
       1. Create tool registry via `createDefaultRegistry(db)`
       2. Create BullMQ Queue instance (`tool-execution`) for dispatching to workers
       3. Start memory consolidation (returns interval handle)
       4. Register shutdown handlers with all resources
       5. Log startup to stderr: `"Jarvis agent started. Tools: {registry.count()}. Consolidation: active."`
       6. Write agent state to Postgres: `agent_state` key=`'system:status'`, value=`{ status: 'running', startedAt: new Date().toISOString(), tools: registry.list() }`

       The main process does NOT start the autonomous planning loop (that's Phase 3). For now it starts, registers everything, writes its state, and waits. This is sufficient to verify Phase 1 infrastructure.

       Export `registry`, `queue`, and `db` for use by future phases.

    Run `pnpm install` from root after creating the package.
  </action>
  <verify>
    - `pnpm --filter @jarvis/agent run build` compiles without errors
    - `DATABASE_URL=... REDIS_URL=... pnpm --filter @jarvis/agent run dev` starts without errors and logs "Jarvis agent started. Tools: 4."
    - Check agent_state table: `SELECT * FROM agent_state WHERE key = 'system:status'` shows running status
    - Start the worker in a separate terminal: `pnpm --filter @jarvis/agent run worker` logs "Worker started"
    - Send SIGTERM to main process: logs "Shutting down..." and exits cleanly
    - Verify Postgres pool is closed (no lingering connections in `pg_stat_activity`)
  </verify>
  <done>
    Main agent process starts, connects to Postgres + Redis, creates tool registry with 4 tools, creates BullMQ queue for worker dispatch, writes system status to agent_state, and shuts down gracefully on SIGTERM. Worker process listens for tool execution jobs and processes them through invokeWithLogging.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement memory consolidation periodic job</name>
  <files>
    apps/agent/src/memory-consolidation.ts
  </files>
  <action>
    Create the memory consolidation job (DATA-06):

    **`apps/agent/src/memory-consolidation.ts`**:

    This is a periodic job that reads recent raw tool outputs and agent decisions from the log tables and distills them into structured facts in `memory_facts`.

    **`startConsolidation(db, intervalMs?: number): NodeJS.Timeout`**:
    - Default interval: 300_000ms (5 minutes)
    - Returns the `setInterval` handle (for cleanup in shutdown)
    - Calls `consolidate(db)` on each interval tick
    - Also calls `consolidate(db)` once immediately at startup

    **`consolidate(db)`** — the core consolidation logic:
    1. Query `tool_calls` for recent completed rows (status='success') not yet consolidated — use a `consolidatedAt` tracking approach: query rows where `startedAt > last consolidation timestamp`. Store last consolidation time in `agent_state` key=`'memory:last_consolidation'`.
    2. For each batch of recent tool results, create a structured fact document:
       ```typescript
       {
         learned: string,        // Summary of what was learned
         confidence: number,     // 0.0-1.0 (1.0 for direct observations, lower for inferences)
         source: string,         // "tool:{toolName}" or "decision:{decisionId}"
         sourceTimestamp: string, // ISO timestamp of the original event
         rawIds: number[],       // IDs of the source log rows
       }
       ```
    3. Insert the fact into `memory_facts` with `subject` describing the topic (e.g., "shell:echo_test_result").
    4. Update `agent_state` key=`'memory:last_consolidation'` with current timestamp.

    **Important design note:** For Phase 1, the consolidation logic is simple — it groups recent tool results by tool name and creates one fact per batch. In later phases (when the LLM is available), consolidation will use the AI to produce smarter summaries. For now, facts are structured summaries of raw tool outputs.

    **Fact permanence:** Per user decision, facts are NEVER deleted. The `isStale` boolean can be set to true but the row persists forever. Do not add any cleanup/deletion logic.

    **`stopConsolidation(handle: NodeJS.Timeout): void`**: Wraps `clearInterval`.
  </action>
  <verify>
    - Start the agent, invoke a few tools through the registry, wait for consolidation interval (or reduce to 5s for testing)
    - Query `memory_facts`: `SELECT * FROM memory_facts ORDER BY created_at DESC LIMIT 10` — should show structured facts from recent tool invocations
    - Verify fact structure: each fact has `subject`, `body` with `learned`, `confidence`, `source`, and `sourceTimestamp` fields
    - Verify consolidation tracks its own progress: `SELECT * FROM agent_state WHERE key = 'memory:last_consolidation'`
    - Run consolidation twice — verify it doesn't duplicate facts from already-processed tool results
    - Verify no DELETE statements exist in the consolidation code (facts are permanent)
  </verify>
  <done>
    Memory consolidation runs every 5 minutes (configurable), reads recent tool results and decisions from log tables, distills them into structured knowledge facts in memory_facts (DATA-06). Facts include subject, learned content, confidence level, source reference, and timestamps. Facts are permanent (never deleted per user decision). Consolidation is idempotent — tracks its last run timestamp to avoid reprocessing.
  </done>
</task>

</tasks>

<verification>
1. Main agent process starts and connects to Postgres + Redis
2. Tool registry has 4 tools registered
3. Worker process starts and listens for jobs
4. Memory consolidation creates facts from tool results (DATA-06)
5. Agent state persists in Postgres (DATA-01 end-to-end)
6. Graceful shutdown closes all connections
7. Working memory is documented as LLM context window (DATA-03 — no implementation needed)
8. Full end-to-end: start agent → invoke tool via registry → check logs → check memory facts → restart → verify state persists
</verification>

<success_criteria>
- `pnpm --filter @jarvis/agent run dev` starts the agent successfully
- Agent writes system:status to agent_state table
- Worker processes tool execution jobs from the queue
- Memory consolidation writes facts to memory_facts table
- SIGTERM triggers graceful shutdown with all connections closed
- After container restart, agent_state retains previous data (DATA-01 persistence)
</success_criteria>

<output>
After completion, create `.planning/phases/01-infrastructure/01-04-SUMMARY.md`
</output>
